{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyON4RqVBGe4g1KKMz+OuPZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanadv/CubixelGAN/blob/main/CubixelGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simplified Cubixel transformation: Convert pixels to Cubixels based on RGB values\n",
        "def pixel_to_cubixel(image):\n",
        "    cubixels = tf.cast(image, tf.float32)  # Ensure the image is in float32\n",
        "\n",
        "    # Separate the R, G, B channels as width, length, and height of Cubixels\n",
        "    cubixel_w = cubixels[:, :, 0]  # Red -> Width\n",
        "    cubixel_l = cubixels[:, :, 1]  # Green -> Length\n",
        "    cubixel_h = cubixels[:, :, 2]  # Blue -> Height\n",
        "\n",
        "    # Combine them into a 3D volume representing the Cubixel dimensions\n",
        "    cubixel_volume = tf.stack([cubixel_w, cubixel_l, cubixel_h], axis=-1)  # Shape (H, W, 3)\n",
        "\n",
        "    # Simply expand the dimensions to include a depth dimension (D = 3 for RGB)\n",
        "    cubixel_volume = tf.expand_dims(cubixel_volume, axis=2)  # Shape (H, W, 1, 3)\n",
        "    return cubixel_volume  # Shape (H, W, D=1, 3)\n",
        "\n",
        "# Define the Generator model (producing simplified Cubixel volumes)\n",
        "def build_generator(latent_dim, img_size):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.Dense(256 * (img_size // 4)**2, activation=\"relu\", input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((img_size // 4, img_size // 4, 256)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2D(3, (3, 3), padding='same', activation='tanh'))  # Produce RGB channels\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the Discriminator model for simplified Cubixel volumes\n",
        "def build_discriminator(img_size):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.InputLayer(input_shape=(img_size, img_size, 3)))  # Simplified input\n",
        "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Volume of Void (VoV) Regularization\n",
        "def compute_vov(cubixels):\n",
        "    # Simplified VoV: Compute the difference between neighboring pixel values in the RGB channels\n",
        "    w = cubixels[:, 1:, :, 0]  # Differences in width (R channel)\n",
        "    prev_w = cubixels[:, :-1, :, 0]\n",
        "\n",
        "    l = cubixels[:, :, 1:, 1]  # Differences in length (G channel)\n",
        "    prev_l = cubixels[:, :, :-1, 1]\n",
        "\n",
        "    h = cubixels[:, :, :, 2]  # Height is constant in this case (B channel)\n",
        "\n",
        "    # Compute absolute differences as a proxy for the \"void\" between adjacent pixels\n",
        "    vov = tf.reduce_mean(tf.abs(w - prev_w)) + tf.reduce_mean(tf.abs(l - prev_l))\n",
        "\n",
        "    return vov\n",
        "\n",
        "\n",
        "# Define the GAN model with the generator, discriminator, and VoV regularization\n",
        "class CubixelGAN(tf.keras.Model):\n",
        "    def __init__(self, generator, discriminator, latent_dim, lambda_vov=10):\n",
        "        super(CubixelGAN, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lambda_vov = lambda_vov\n",
        "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer):\n",
        "        super(CubixelGAN, self).compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "\n",
        "    def g_loss_fn(self, fake_output):\n",
        "        return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    def d_loss_fn(self, real_output, fake_output):\n",
        "        real_loss = self.cross_entropy(tf.ones_like(real_output) * 0.9, real_output)  # Label smoothing\n",
        "        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Train the generator\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            generated_images = self.generator(random_latent_vectors)\n",
        "            fake_output = self.discriminator(generated_images)\n",
        "            g_loss = self.g_loss_fn(fake_output)\n",
        "            vov_loss = compute_vov(generated_images)\n",
        "            total_g_loss = g_loss + self.lambda_vov * vov_loss\n",
        "\n",
        "        g_gradients = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            real_output = self.discriminator(real_images)\n",
        "            fake_output = self.discriminator(generated_images)\n",
        "            d_loss = self.d_loss_fn(real_output, fake_output)\n",
        "\n",
        "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "        return {\"g_loss\": g_loss, \"d_loss\": d_loss, \"vov_loss\": vov_loss}\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "img_size = 32\n",
        "epochs = 100  # Reduced epoch count for faster convergence\n",
        "batch_size = 32\n",
        "lambda_vov = 5\n",
        "\n",
        "# Initialize models\n",
        "generator = build_generator(latent_dim, img_size)\n",
        "discriminator = build_discriminator(img_size)\n",
        "cubixel_gan = CubixelGAN(generator, discriminator, latent_dim, lambda_vov)\n",
        "\n",
        "# Compile the GAN with reduced learning rates and TTUR\n",
        "cubixel_gan.compile(\n",
        "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Slower learning rate for generator\n",
        "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0004)   # Faster learning rate for discriminator\n",
        ")\n",
        "\n",
        "# Load CIFAR-10 data and convert it to Cubixel volumes\n",
        "def convert_to_cubixels(images):\n",
        "    return pixel_to_cubixel(images)\n",
        "\n",
        "# Load CIFAR-10 dataset and convert images to Cubixels\n",
        "(ds_train, _), ds_info = tfds.load('cifar10', split=['train', 'test'], with_info=True)\n",
        "ds_train = ds_train.map(lambda x: (tf.cast(x['image'], tf.float32) / 127.5) - 1.0)  # Normalize images\n",
        "ds_train = ds_train.batch(batch_size)\n",
        "\n",
        "# Train the GAN\n",
        "cubixel_gan.fit(ds_train, epochs=epochs)\n",
        "\n",
        "# Generate and visualize Cubixel volumes\n",
        "def generate_and_plot_cubixels(generator, latent_dim):\n",
        "    random_latent_vectors = tf.random.normal(shape=(16, latent_dim))\n",
        "    generated_images = generator(random_latent_vectors)\n",
        "    generated_images = (generated_images + 1) / 2.0  # Rescale to [0, 1]\n",
        "\n",
        "    fig, axs = plt.subplots(4, 4, figsize=(8, 8))\n",
        "    count = 0\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            axs[i, j].imshow(generated_images[count][:, :, :])  # Visualizing the Cubixel image\n",
        "            axs[i, j].axis('off')\n",
        "            count += 1\n",
        "    plt.show()\n",
        "\n",
        "generate_and_plot_cubixels(generator, latent_dim)\n"
      ],
      "metadata": {
        "id": "30Q5Nsvdonql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Function to generate and save images in a zip file\n",
        "def generate_save_and_zip(generator, latent_dim, zip_filename='generated_images.zip'):\n",
        "    save_dir = 'generated_images'\n",
        "\n",
        "    # Ensure the save directory exists\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    random_latent_vectors = tf.random.normal(shape=(16, latent_dim))\n",
        "    generated_images = generator(random_latent_vectors)\n",
        "    generated_images = (generated_images + 1) / 2.0  # Rescale to [0, 1]\n",
        "\n",
        "    # Save each image as a PNG file\n",
        "    for i, img in enumerate(generated_images):\n",
        "        img_np = img.numpy()  # Convert tensor to numpy array\n",
        "        img_np = np.clip(img_np * 255, 0, 255).astype(np.uint8)  # Convert to uint8 format\n",
        "\n",
        "        # Save the image\n",
        "        plt.imsave(f\"{save_dir}/generated_image_{i+1}.png\", img_np)\n",
        "\n",
        "    # Create a zip file containing all generated images\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for root, dirs, files in os.walk(save_dir):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file))\n",
        "\n",
        "    return zip_filename\n",
        "\n",
        "# Generate, save, and zip the images\n",
        "zip_filename = generate_save_and_zip(generator, latent_dim)\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "id": "dXPVVug5qZUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "# Create directories to save images for FID calculation\n",
        "real_image_dir = 'real_images'\n",
        "generated_image_dir = 'generated_images'\n",
        "\n",
        "if not os.path.exists(real_image_dir):\n",
        "    os.makedirs(real_image_dir)\n",
        "if not os.path.exists(generated_image_dir):\n",
        "    os.makedirs(generated_image_dir)\n",
        "\n",
        "# Function to save images to directories\n",
        "def save_images_to_dir(images, directory, prefix):\n",
        "    for i, img in enumerate(images[:100]):  # Limiting to 100 images for FID\n",
        "        img = (img + 1) * 127.5  # Rescale to [0, 255]\n",
        "        img = img.numpy().astype(np.uint8)  # Convert to uint8\n",
        "        img_path = os.path.join(directory, f'{prefix}_{i}.png')\n",
        "        cv2.imwrite(img_path, img)\n",
        "\n",
        "# Cubixel transformation: Convert pixels to Cubixels based on RGB values\n",
        "def pixel_to_cubixel(image):\n",
        "    cubixels = tf.cast(image, tf.float32)\n",
        "\n",
        "    cubixel_w = cubixels[:, :, 0]  # Red -> Width\n",
        "    cubixel_l = cubixels[:, :, 1]  # Green -> Length\n",
        "    cubixel_h = cubixels[:, :, 2]  # Blue -> Height\n",
        "\n",
        "    cubixel_volume = tf.stack([cubixel_w, cubixel_l, cubixel_h], axis=-1)\n",
        "    cubixel_volume = tf.expand_dims(cubixel_volume, axis=2)  # Add depth axis (H, W, 1, 3)\n",
        "    return cubixel_volume\n",
        "\n",
        "# Define the Generator model\n",
        "def build_generator(latent_dim, img_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(256 * (img_size // 4)**2, activation=\"relu\", input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((img_size // 4, img_size // 4, 256)))\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Conv2D(3, (3, 3), padding='same', activation='tanh'))  # Output RGB channels\n",
        "    return model\n",
        "\n",
        "# Define the Discriminator model\n",
        "def build_discriminator(img_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(img_size, img_size, 3)))\n",
        "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Volume of Void (VoV) Regularization: Penalize large differences in cubixels\n",
        "def compute_vov(cubixels):\n",
        "    w = cubixels[:, 1:, :, 0]\n",
        "    prev_w = cubixels[:, :-1, :, 0]\n",
        "    l = cubixels[:, :, 1:, 1]\n",
        "    prev_l = cubixels[:, :, :-1, 1]\n",
        "    vov = tf.reduce_mean(tf.abs(w - prev_w)) + tf.reduce_mean(tf.abs(l - prev_l))\n",
        "    return vov\n",
        "\n",
        "# Define the GAN model with the generator, discriminator, and VoV regularization\n",
        "class CubixelGAN(tf.keras.Model):\n",
        "    def __init__(self, generator, discriminator, latent_dim, lambda_vov=10):\n",
        "        super(CubixelGAN, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lambda_vov = lambda_vov\n",
        "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer):\n",
        "        super(CubixelGAN, self).compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "\n",
        "    def g_loss_fn(self, fake_output):\n",
        "        return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    def d_loss_fn(self, real_output, fake_output):\n",
        "        real_loss = self.cross_entropy(tf.ones_like(real_output) * 0.9, real_output)\n",
        "        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Train the generator\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            generated_images = self.generator(random_latent_vectors)\n",
        "            fake_output = self.discriminator(generated_images)\n",
        "            g_loss = self.g_loss_fn(fake_output)\n",
        "            vov_loss = compute_vov(generated_images)\n",
        "            total_g_loss = g_loss + self.lambda_vov * vov_loss\n",
        "\n",
        "        g_gradients = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            real_images_reshaped = tf.reshape(real_images, [-1, img_size, img_size, 3])  # Reshape to match the expected shape\n",
        "            real_output = self.discriminator(real_images_reshaped)\n",
        "            fake_output = self.discriminator(generated_images)\n",
        "            d_loss = self.d_loss_fn(real_output, fake_output)\n",
        "\n",
        "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "        return {\"g_loss\": g_loss, \"d_loss\": d_loss, \"vov_loss\": vov_loss}\n",
        "\n",
        "# FID calculation functions\n",
        "def calculate_fid(real_images, generated_images):\n",
        "    # Ensure both real and generated images have correct 4D shape\n",
        "    real_images = tf.reshape(real_images, (-1, img_size, img_size, 3))\n",
        "    generated_images = tf.reshape(generated_images, (-1, img_size, img_size, 3))\n",
        "\n",
        "    # Load InceptionV3 model\n",
        "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
        "\n",
        "    # Resize images to (299, 299) and preprocess\n",
        "    real_images_resized = tf.image.resize(real_images, (299, 299))\n",
        "    generated_images_resized = tf.image.resize(generated_images, (299, 299))\n",
        "\n",
        "    # Preprocess images for InceptionV3\n",
        "    real_images_resized = preprocess_input(real_images_resized)\n",
        "    generated_images_resized = preprocess_input(generated_images_resized)\n",
        "\n",
        "    # Get the activations\n",
        "    real_activations = model.predict(real_images_resized)\n",
        "    generated_activations = model.predict(generated_images_resized)\n",
        "\n",
        "    # Calculate mean and covariance of activations\n",
        "    mu_real = np.mean(real_activations, axis=0)\n",
        "    sigma_real = np.cov(real_activations, rowvar=False)\n",
        "    mu_generated = np.mean(generated_activations, axis=0)\n",
        "    sigma_generated = np.cov(generated_activations, rowvar=False)\n",
        "\n",
        "    # Calculate FID score\n",
        "    ssdiff = np.sum((mu_real - mu_generated)**2.0)\n",
        "    covmean, _ = sqrtm(sigma_real.dot(sigma_generated), disp=False)\n",
        "\n",
        "    # Handle complex numbers from sqrtm\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = ssdiff + np.trace(sigma_real + sigma_generated - 2.0 * covmean)\n",
        "    return fid\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "img_size = 32\n",
        "epochs = 1\n",
        "batch_size = 32\n",
        "lambda_vov = 5\n",
        "\n",
        "# Initialize models\n",
        "generator = build_generator(latent_dim, img_size)\n",
        "discriminator = build_discriminator(img_size)\n",
        "cubixel_gan = CubixelGAN(generator, discriminator, latent_dim, lambda_vov)\n",
        "\n",
        "# Compile the GAN\n",
        "cubixel_gan.compile(\n",
        "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0004)\n",
        ")\n",
        "\n",
        "# Load CIFAR-10 dataset and convert images to Cubixels\n",
        "(ds_train, ds_test), ds_info = tfds.load('cifar10', split=['train', 'test'], with_info=True)\n",
        "ds_train = ds_train.map(lambda x: pixel_to_cubixel((tf.cast(x['image'], tf.float32) / 127.5) - 1.0)).batch(batch_size)\n",
        "\n",
        "# Train the GAN\n",
        "cubixel_gan.fit(ds_train, epochs=epochs)\n",
        "\n",
        "# Generate images for FID calculation\n",
        "real_images = next(iter(ds_train))[:100]  # Limiting to 100 real images\n",
        "random_latent_vectors = tf.random.normal(shape=(100, latent_dim))\n",
        "generated_images = generator(random_latent_vectors)\n",
        "\n",
        "# Calculate FID\n",
        "fid_score = calculate_fid(real_images, generated_images)\n",
        "print(f\"FID Score: {fid_score}\")\n"
      ],
      "metadata": {
        "id": "z5cWyvuD166V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}